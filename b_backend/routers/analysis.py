"""
è‚¡ç¥¨åˆ†æè·¯ç”±
"""

from fastapi import APIRouter, HTTPException, BackgroundTasks
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from datetime import datetime, date
import logging
import uuid
import asyncio

router = APIRouter()
logger = logging.getLogger("tradingagents-api")

# å†…å­˜å­˜å‚¨åˆ†æä»»åŠ¡ï¼ˆç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨æ•°æ®åº“ï¼‰
analysis_tasks: Dict[str, Dict[str, Any]] = {}


# è¯·æ±‚æ¨¡å‹
class AnalysisRequest(BaseModel):
    """åˆ†æè¯·æ±‚æ¨¡å‹"""
    symbol: str = Field(..., description="è‚¡ç¥¨ä»£ç ï¼Œå¦‚ NVDA, AAPL")
    analysis_date: Optional[str] = Field(
        default=None, 
        description="åˆ†ææ—¥æœŸï¼Œæ ¼å¼ YYYY-MM-DD"
    )
    research_depth: int = Field(
        default=1, 
        ge=1, 
        le=3, 
        description="ç ”ç©¶æ·±åº¦ï¼š1=å¿«é€Ÿ, 2=æ ‡å‡†, 3=æ·±åº¦"
    )
    selected_analysts: List[str] = Field(
        default=["market", "news", "fundamentals"],
        description="é€‰æ‹©çš„åˆ†æå¸ˆå›¢é˜Ÿ"
    )


class BatchAnalysisRequest(BaseModel):
    """æ‰¹é‡åˆ†æè¯·æ±‚"""
    symbols: List[str] = Field(..., description="è‚¡ç¥¨ä»£ç åˆ—è¡¨")
    analysis_date: Optional[str] = None
    research_depth: int = Field(default=1, ge=1, le=3)
    selected_analysts: List[str] = Field(
        default=["market", "news", "fundamentals"]
    )


# å“åº”æ¨¡å‹
class AnalysisResponse(BaseModel):
    """åˆ†æå“åº”æ¨¡å‹"""
    success: bool
    task_id: str
    message: str


class TaskStatusResponse(BaseModel):
    """ä»»åŠ¡çŠ¶æ€å“åº”"""
    task_id: str
    status: str  # pending, running, completed, failed
    progress: int
    message: str
    result: Optional[Dict[str, Any]] = None
    created_at: str
    updated_at: str


# åˆ†æå¸ˆä¿¡æ¯
ANALYSTS_INFO = {
    "market": {
        "name": "å¸‚åœºåˆ†æå¸ˆ",
        "icon": "ğŸ“ˆ",
        "description": "åˆ†æè‚¡ç¥¨ä»·æ ¼èµ°åŠ¿ã€æŠ€æœ¯æŒ‡æ ‡"
    },
    "social": {
        "name": "ç¤¾åª’åˆ†æå¸ˆ",
        "icon": "ğŸ“±",
        "description": "åˆ†æç¤¾äº¤åª’ä½“æƒ…ç»ªå’Œèˆ†è®º"
    },
    "news": {
        "name": "æ–°é—»åˆ†æå¸ˆ",
        "icon": "ğŸ“°",
        "description": "åˆ†æç›¸å…³æ–°é—»å’Œè¡Œä¸šåŠ¨æ€"
    },
    "fundamentals": {
        "name": "åŸºæœ¬é¢åˆ†æå¸ˆ",
        "icon": "ğŸ“Š",
        "description": "åˆ†æå…¬å¸è´¢åŠ¡çŠ¶å†µå’ŒåŸºæœ¬é¢"
    }
}


async def run_analysis_task(task_id: str, request: AnalysisRequest):
    """æ‰§è¡Œåˆ†æä»»åŠ¡ï¼ˆå¼‚æ­¥åå°ä»»åŠ¡ï¼‰"""
    try:
        logger.info(f"ğŸš€ å¼€å§‹åˆ†æä»»åŠ¡: {task_id}, è‚¡ç¥¨: {request.symbol}")
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        analysis_tasks[task_id]["status"] = "running"
        analysis_tasks[task_id]["progress"] = 10
        analysis_tasks[task_id]["message"] = "æ­£åœ¨åˆå§‹åŒ–åˆ†æå¼•æ“..."
        analysis_tasks[task_id]["updated_at"] = datetime.utcnow().isoformat()
        
        await asyncio.sleep(1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        
        # å°è¯•å¯¼å…¥å¹¶ä½¿ç”¨ TradingAgents
        try:
            from tradingagents.graph.trading_graph import TradingAgentsGraph
            from tradingagents.default_config import DEFAULT_CONFIG
            
            # æ›´æ–°è¿›åº¦
            analysis_tasks[task_id]["progress"] = 20
            analysis_tasks[task_id]["message"] = "æ­£åœ¨é…ç½®åˆ†æå‚æ•°..."
            analysis_tasks[task_id]["updated_at"] = datetime.utcnow().isoformat()
            
            await asyncio.sleep(0.5)
            
            # åˆ›å»ºé…ç½®
            config = DEFAULT_CONFIG.copy()
            config["max_debate_rounds"] = request.research_depth
            
            # æ›´æ–°è¿›åº¦
            analysis_tasks[task_id]["progress"] = 30
            analysis_tasks[task_id]["message"] = "æ­£åœ¨åˆå§‹åŒ–AIæ™ºèƒ½ä½“..."
            analysis_tasks[task_id]["updated_at"] = datetime.utcnow().isoformat()
            
            await asyncio.sleep(0.5)
            
            # åˆå§‹åŒ–å›¾
            ta = TradingAgentsGraph(
                selected_analysts=request.selected_analysts,
                debug=True,
                config=config
            )
            
            # æ›´æ–°è¿›åº¦
            analysis_tasks[task_id]["progress"] = 50
            analysis_tasks[task_id]["message"] = "AIåˆ†æå¸ˆå›¢é˜Ÿæ­£åœ¨åˆ†æä¸­..."
            analysis_tasks[task_id]["updated_at"] = datetime.utcnow().isoformat()
            
            # ç¡®å®šåˆ†ææ—¥æœŸ
            analysis_date = request.analysis_date or date.today().strftime("%Y-%m-%d")
            
            # æ‰§è¡Œåˆ†æï¼ˆè¿™æ˜¯åŒæ­¥æ“ä½œï¼Œåœ¨çœŸå®åœºæ™¯ä¸­åº”è¯¥ä½¿ç”¨çº¿ç¨‹æ± ï¼‰
            loop = asyncio.get_event_loop()
            _, decision = await loop.run_in_executor(
                None, 
                lambda: ta.propagate(request.symbol, analysis_date)
            )
            
            # æ›´æ–°è¿›åº¦
            analysis_tasks[task_id]["progress"] = 90
            analysis_tasks[task_id]["message"] = "æ­£åœ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š..."
            analysis_tasks[task_id]["updated_at"] = datetime.utcnow().isoformat()
            
            await asyncio.sleep(0.5)
            
            # å®Œæˆåˆ†æ
            analysis_tasks[task_id]["status"] = "completed"
            analysis_tasks[task_id]["progress"] = 100
            analysis_tasks[task_id]["message"] = "åˆ†æå®Œæˆ"
            analysis_tasks[task_id]["result"] = {
                "symbol": request.symbol,
                "analysis_date": analysis_date,
                "decision": decision,
                "analysts_used": request.selected_analysts,
                "research_depth": request.research_depth
            }
            analysis_tasks[task_id]["updated_at"] = datetime.utcnow().isoformat()
            
            logger.info(f"âœ… åˆ†æä»»åŠ¡å®Œæˆ: {task_id}")
            
        except ImportError as e:
            logger.warning(f"âš ï¸ TradingAgents å¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®: {e}")
            
            # æ¨¡æ‹Ÿåˆ†æè¿‡ç¨‹
            steps = [
                (20, "æ­£åœ¨è·å–è‚¡ç¥¨æ•°æ®..."),
                (40, "å¸‚åœºåˆ†æå¸ˆæ­£åœ¨åˆ†ææŠ€æœ¯æŒ‡æ ‡..."),
                (60, "æ–°é—»åˆ†æå¸ˆæ­£åœ¨åˆ†æç›¸å…³æ–°é—»..."),
                (80, "åŸºæœ¬é¢åˆ†æå¸ˆæ­£åœ¨åˆ†æè´¢åŠ¡æ•°æ®..."),
                (90, "ç ”ç©¶å›¢é˜Ÿæ­£åœ¨è®¨è®ºå’Œè¾©è®º..."),
                (95, "æ­£åœ¨ç”Ÿæˆæœ€ç»ˆå†³ç­–...")
            ]
            
            for progress, message in steps:
                analysis_tasks[task_id]["progress"] = progress
                analysis_tasks[task_id]["message"] = message
                analysis_tasks[task_id]["updated_at"] = datetime.utcnow().isoformat()
                await asyncio.sleep(1.5)
            
            # ç”Ÿæˆæ¨¡æ‹Ÿç»“æœ
            analysis_date = request.analysis_date or date.today().strftime("%Y-%m-%d")
            analysis_tasks[task_id]["status"] = "completed"
            analysis_tasks[task_id]["progress"] = 100
            analysis_tasks[task_id]["message"] = "åˆ†æå®Œæˆ"
            analysis_tasks[task_id]["result"] = {
                "symbol": request.symbol,
                "analysis_date": analysis_date,
                "decision": {
                    "action": "HOLD",
                    "confidence": 0.75,
                    "summary": f"åŸºäºå¯¹ {request.symbol} çš„ç»¼åˆåˆ†æï¼ŒAI åˆ†æå¸ˆå›¢é˜Ÿå»ºè®®æŒæœ‰è§‚æœ›ã€‚æŠ€æœ¯æŒ‡æ ‡æ˜¾ç¤ºè‚¡ä»·å¤„äºç›˜æ•´é˜¶æ®µï¼ŒåŸºæœ¬é¢ç¨³å¥ï¼Œå»ºè®®å¯†åˆ‡å…³æ³¨å¸‚åœºåŠ¨æ€åå†åšå†³ç­–ã€‚",
                    "technical_analysis": "æŠ€æœ¯æŒ‡æ ‡æ˜¾ç¤ºRSIå¤„äºä¸­æ€§åŒºé—´ï¼ŒMACDå‘ˆç°å¼±å¤šå¤´ä¿¡å·ï¼ŒçŸ­æœŸå‡çº¿ä¸é•¿æœŸå‡çº¿æ¥è¿‘äº¤å‰ã€‚",
                    "fundamental_analysis": "å…¬å¸è´¢åŠ¡çŠ¶å†µè‰¯å¥½ï¼Œè¥æ”¶å¢é•¿ç¨³å®šï¼Œä½†ä¼°å€¼ç›¸å¯¹è¾ƒé«˜ã€‚",
                    "news_sentiment": "è¿‘æœŸæ–°é—»æƒ…ç»ªåä¸­æ€§ï¼Œæ²¡æœ‰é‡å¤§åˆ©å¥½æˆ–åˆ©ç©ºæ¶ˆæ¯ã€‚",
                    "risk_assessment": "å½“å‰å¸‚åœºæ³¢åŠ¨æ€§è¾ƒé«˜ï¼Œå»ºè®®æ§åˆ¶ä»“ä½ï¼Œè®¾ç½®æ­¢æŸä½ã€‚"
                },
                "analysts_used": request.selected_analysts,
                "research_depth": request.research_depth,
                "is_simulated": True
            }
            analysis_tasks[task_id]["updated_at"] = datetime.utcnow().isoformat()
            
            logger.info(f"âœ… åˆ†æä»»åŠ¡å®Œæˆï¼ˆæ¨¡æ‹Ÿï¼‰: {task_id}")
            
    except Exception as e:
        logger.error(f"âŒ åˆ†æä»»åŠ¡å¤±è´¥: {task_id}, é”™è¯¯: {e}", exc_info=True)
        analysis_tasks[task_id]["status"] = "failed"
        analysis_tasks[task_id]["message"] = f"åˆ†æå¤±è´¥: {str(e)}"
        analysis_tasks[task_id]["updated_at"] = datetime.utcnow().isoformat()


@router.post("/single", response_model=Dict[str, Any])
async def submit_analysis(
    request: AnalysisRequest,
    background_tasks: BackgroundTasks
):
    """æäº¤å•è‚¡åˆ†æä»»åŠ¡"""
    try:
        logger.info(f"ğŸ“Š æ”¶åˆ°åˆ†æè¯·æ±‚: {request.symbol}")
        
        # åˆ›å»ºä»»åŠ¡ID
        task_id = str(uuid.uuid4())
        
        # åˆå§‹åŒ–ä»»åŠ¡è®°å½•
        analysis_tasks[task_id] = {
            "task_id": task_id,
            "status": "pending",
            "progress": 0,
            "message": "ä»»åŠ¡å·²åˆ›å»ºï¼Œç­‰å¾…å¤„ç†...",
            "request": request.model_dump(),
            "result": None,
            "created_at": datetime.utcnow().isoformat(),
            "updated_at": datetime.utcnow().isoformat()
        }
        
        # æ·»åŠ åå°ä»»åŠ¡
        background_tasks.add_task(run_analysis_task, task_id, request)
        
        return {
            "success": True,
            "data": {
                "task_id": task_id,
                "status": "pending",
                "message": "åˆ†æä»»åŠ¡å·²æäº¤"
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ æäº¤åˆ†æä»»åŠ¡å¤±è´¥: {e}")
        raise HTTPException(status_code=400, detail=str(e))


@router.get("/tasks/{task_id}/status")
async def get_task_status(task_id: str):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    if task_id not in analysis_tasks:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    task = analysis_tasks[task_id]
    return {
        "success": True,
        "data": {
            "task_id": task["task_id"],
            "status": task["status"],
            "progress": task["progress"],
            "message": task["message"],
            "created_at": task["created_at"],
            "updated_at": task["updated_at"]
        }
    }


@router.get("/tasks/{task_id}/result")
async def get_task_result(task_id: str):
    """è·å–ä»»åŠ¡ç»“æœ"""
    if task_id not in analysis_tasks:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    task = analysis_tasks[task_id]
    
    if task["status"] != "completed":
        return {
            "success": False,
            "message": f"ä»»åŠ¡å°šæœªå®Œæˆï¼Œå½“å‰çŠ¶æ€: {task['status']}",
            "data": {
                "task_id": task["task_id"],
                "status": task["status"],
                "progress": task["progress"]
            }
        }
    
    return {
        "success": True,
        "data": task["result"]
    }


@router.get("/tasks")
async def list_tasks(
    status: Optional[str] = None,
    limit: int = 20
):
    """è·å–ä»»åŠ¡åˆ—è¡¨"""
    tasks = list(analysis_tasks.values())
    
    # æŒ‰çŠ¶æ€ç­›é€‰
    if status:
        tasks = [t for t in tasks if t["status"] == status]
    
    # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    tasks.sort(key=lambda x: x["created_at"], reverse=True)
    
    # é™åˆ¶æ•°é‡
    tasks = tasks[:limit]
    
    return {
        "success": True,
        "data": {
            "tasks": tasks,
            "total": len(tasks)
        }
    }


@router.get("/analysts")
async def get_analysts():
    """è·å–å¯ç”¨çš„åˆ†æå¸ˆåˆ—è¡¨"""
    return {
        "success": True,
        "data": ANALYSTS_INFO
    }


@router.delete("/tasks/{task_id}")
async def delete_task(task_id: str):
    """åˆ é™¤ä»»åŠ¡"""
    if task_id not in analysis_tasks:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    del analysis_tasks[task_id]
    
    return {
        "success": True,
        "message": "ä»»åŠ¡å·²åˆ é™¤"
    }
